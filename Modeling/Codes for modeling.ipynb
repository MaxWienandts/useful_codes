{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75236829-d7db-4ea6-bf4e-ba4003bc230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from IPython.display import display\n",
    "# from bbmagic import Hdfs\n",
    "\n",
    "from trata_variaveis import trata_variaveis_categoricas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imblearn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders.target_encoder import OrdinalEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8340e17a-5132-46ca-9e0b-6677bd84836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('df.csv', index = False)   # If index = True, it will be created a new columns with the index.\n",
    "\n",
    "df = pd.read_csv('df.csv')\n",
    "\n",
    "# Select only useful coluns for the model.\n",
    "df = df[['year_month', 'target', 'col_4', 'col_5', 'col_6', 'col_7', 'value']]   \n",
    "\n",
    "print('Observations:', len(df)) # XX.XXX\n",
    "print('Variables:', df.shape[1]) # XX\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e39bf0-6f5c-45f2-b77f-57b84d28cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o out of time\n",
    "df_out_of_time = df[df[\"year_month\"].isin([202111, 202112]) == True].copy()\n",
    "df_out_of_time = df_out_of_time.drop('year_month', axis = 1).copy()\n",
    "\n",
    "df_model = df[df[\"year_month\"].isin([202111, 202112]) == False].copy()\n",
    "df_model = df_model.drop(['year_month', 'value'], axis = 1).copy()\n",
    "\n",
    "\n",
    "print('Observations:', len(df)) # XX.XXX\n",
    "print('Variables:', df.shape[1]) # XX\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1f6a8-3b78-4ee6-b09a-b12c6608ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how many variables we should use in the XGBoost. \n",
    "# This algorithm uses the forward method.\n",
    "# First, it makes several models with only one variable and select the best one. After, select the best model with two variables given that one variable was already selected in the previous step. \n",
    "# It repeats the steps until making a model with all variables.\n",
    "xgb_hyperparameters_dict = { 'objective': 'binary:logistic', \n",
    "                            'use_label_encoder': False,             # Necessary only when using the scikit-learn api.\n",
    "                            'eval_metric': 'auc', \n",
    "                            'verbosity': 1, \n",
    "                            'validate_parameters': True, \n",
    "                            'tree_method': \"hist\",     \n",
    "                            'booster': 'gbtree',       # gbtree, gblinear or dart. \\\n",
    "                            }\n",
    "# Cross-validation\n",
    "# Dataframes with the best variables and ROC_AUC.\n",
    "df_auc_roc = pd.DataFrame()\n",
    "df_variables = pd.DataFrame()\n",
    "for cross_i in range(0, 10):\n",
    "    # Use bootstrap to generate train and test.\n",
    "    df_train_bootstrap = df_model.sample(len(df_model), replace=True).copy()\n",
    "    df_test_bootstrap = df_model[~df_model.index.isin(df_train_bootstrap.index.to_list())].copy()\n",
    "\n",
    "    y_train = df_train_bootstrap['target']\n",
    "    df_train_bootstrap = df_train_bootstrap.drop('target', axis = 1)\n",
    "    y_test = df_test_bootstrap['target']\n",
    "    df_test_bootstrap = df_test_bootstrap.drop('target', axis = 1)\n",
    "\n",
    "    # Define the categorical variables\n",
    "    categorical_variables = ['col_6', 'col_7']\n",
    "    # Define the categorical variables\n",
    "    scalar_variables = ['col_4', 'col_5\n",
    "\n",
    "    # Fill the nulls using the median of the train dataset.\n",
    "    median_dict = {}\n",
    "    for col in df_train_bootstrap[scalar_variables]:\n",
    "        median_dict[col] = df_train_bootstrap[col].median()\n",
    "    for key in median_dict:\n",
    "        df_train_bootstrap[key] = df_train_bootstrap[key].fillna(median_dict[key])\n",
    "        df_test_bootstrap[key] = df_test_bootstrap[key].fillna(median_dict[key])\n",
    "\n",
    "    # Normalizeing is import if we want to use regularization.\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_train_bootstrap[scalar_variables])\n",
    "    df_train_bootstrap[scalar_variables] = scaler.transform(df_train_bootstrap[scalar_variables])\n",
    "    df_test_bootstrap[scalar_variables] = scaler.transform(df_test_bootstrap[scalar_variables])\n",
    "\n",
    "    # target encoder for categorical varibles.\n",
    "    target_encoder_dict = {}\n",
    "    for col in df_train_bootstrap[categorical_variables]:\n",
    "        target_encoder_dict[col] = TargetEncoder().fit(df_train_bootstrap[col], y_train)\n",
    "    for key in target_encoder_dict:\n",
    "        df_train_bootstrap[key] = target_encoder_dict[key].transform(df_train_bootstrap[key])\n",
    "        df_test_bootstrap[key] = target_encoder_dict[key].transform(df_test_bootstrap[key])\n",
    "\n",
    "    \n",
    "    auc_roc = []\n",
    "    variables = ['target']\n",
    "    columns = df_train_bootstrap.columns\n",
    "\n",
    "    for i in range(0, len(columns)):\n",
    "        auc_roc_best = 0\n",
    "        variables_test = []\n",
    "        variables_best = []\n",
    "\n",
    "        for j in range(0, len(columns)):\n",
    "            variables_test_aux = variables + [columns[j]]\n",
    "            variables_test = pd.unique(variables_test_aux)\n",
    "\n",
    "            if (len(variables_test) == len(variables_test_aux)):   # So we don't test the same model twice.\n",
    "                XGBoost = xgb.XGBRegressor(**xgb_hyperparameters_dict)\n",
    "                # fit and predict\n",
    "                variables_test\n",
    "                XGBoost_fit = XGBoost.fit(df_train_bootstrap[variables_test[1:]], y_train)\n",
    "                y_pred_test = XGBoost_fit.predict(df_test_bootstrap[variables_test[1:]])\n",
    "                auc_roc_aux = roc_auc_score(y_test, y_pred_test)\n",
    "                if auc_roc_aux > auc_roc_best:\n",
    "                    variables_best = columns[j]\n",
    "                    auc_roc_best = auc_roc_aux\n",
    "\n",
    "        variables = variables + [variables_best]\n",
    "        auc_roc = auc_roc + [auc_roc_best]\n",
    "    # Save final results    \n",
    "    df_variables[cross_i] = variables\n",
    "    df_auc_roc[cross_i] = auc_roc\n",
    "    print(cross_i)\n",
    "variables_count = np.arange(start = 1, stop = len(variables), step = 1)\n",
    "df_variables['qnt_variables'] = df_variables.index\n",
    "df_auc_roc['qnt_variables'] = variables_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75faa6b2-1ce0-4dcb-a43c-2114679379c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxpot of ROC per quantity of variables used\n",
    "df_auc_roc_2 = pd.melt(df_auc_roc, id_vars = ['qnt_variables'], value_vars = [0, 1, 2], var_name = 'cros_val', value_name = 'roc_auc')\n",
    "title = 'Performance by used variables' \n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "sns.set(rc = {'figure.figsize': (10, 6)})\n",
    "bg_color = \"white\"\n",
    "contorno = 'black'\n",
    "color = 'black'\n",
    "sns.set_style(\"darkgrid\", {'axes.facecolor': bg_color\n",
    "                          , 'axes.edgecolor': contorno})\n",
    "meanpointprops = dict(color = color, linewidth = 1.5)\n",
    "\n",
    "ax = sns.boxplot(y = 'roc_auc', data = df_auc_roc_2, x = 'qnt_variables'  #, order = hue_order\n",
    "                    , showmeans = True, meanline = True, meanprops = meanpointprops)\n",
    "ax.set_title(title, fontsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77bd9a-d955-4e60-9024-5d5317a19603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify which variables were used for each model. \n",
    "# There are some randomness in each model. Therefore, we need a heat map showing the proportion of how many times each variable was used in the cross-validation. \n",
    "df_variables_heatmap = (df_variables.iloc[1:,:-1].apply(pd.Series.value_counts, axis=1).fillna(0)) / 10\n",
    "df_variables_heatmap = df_variables_heatmap.cumsum()\n",
    "df_variables_heatmap = df_variables_heatmap.replace({0: np.nan})\n",
    "\n",
    "size_x = 10\n",
    "size_y = 10\n",
    "plt.figure(figsize = (size_x, size_y))\n",
    "sns.set(font_scale = 1)\n",
    "corr_matrix = df.corr()\n",
    "with sns.axes_style('white'):\n",
    "    ax = sns.heatmap(df_variables_heatmap.T\n",
    "                    , linewidth = 0.2\n",
    "                    , annot = True, fmt = '.1f'\n",
    "                    , cmap = 'seismic'\n",
    "                    , vmin = -1, vmax = 1)\n",
    "plt.title(title)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83bb1b7-4d8b-45ea-977f-911b128c9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how many variables we should use in the LightGbM. \n",
    "# This algorithm uses the forward method.\n",
    "# First, it makes several models with only one variable and select the best one. After, select the best model with two variables given that one variable was already selected in the previous step. \n",
    "# It repeats the steps until making a model with all variables.\n",
    "hyperparameters_LightGBM_dict = {\"objective\": \"binary\",\n",
    "            \"metric\": \"binary_logloss\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            'verbose': -1,\n",
    "            } \n",
    "\n",
    "# Cross-validation\n",
    "# Dataframes with the best variables and ROC_AUC.\n",
    "df_variables_lightgbm = pd.DataFrame()\n",
    "df_auc_roc_lightgbm = pd.DataFrame()\n",
    "for cross_i in range(0, 10):\n",
    "    # Use bootstrap to generate train and test.\n",
    "    df_train_bootstrap = df_model.sample(len(df_model), replace=True).copy()\n",
    "    df_test_bootstrap = df_model[~df_model.index.isin(df_train_bootstrap.index.to_list())].copy()\n",
    "\n",
    "    y_train = df_train_bootstrap['target']\n",
    "    df_train_bootstrap = df_train_bootstrap.drop('target', axis = 1)\n",
    "    y_test = df_test_bootstrap['target']\n",
    "    df_test_bootstrap = df_test_bootstrap.drop('target', axis = 1)\n",
    "\n",
    "    # Define the categorical variables\n",
    "    categorical_variables = ['col_6', 'col_7']\n",
    "    # Define the categorical variables\n",
    "    scalar_variables = ['col_4', 'col_5\n",
    "\n",
    "    # Fill the nulls using the median of the train dataset.\n",
    "    median_dict = {}\n",
    "    for col in df_train_bootstrap[scalar_variables]:\n",
    "        median_dict[col] = df_train_bootstrap[col].median()\n",
    "    for key in median_dict:\n",
    "        df_train_bootstrap[key] = df_train_bootstrap[key].fillna(median_dict[key])\n",
    "        df_test_bootstrap[key] = df_test_bootstrap[key].fillna(median_dict[key])\n",
    "\n",
    "    # Normalizeing is import if we want to use regularization.\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_train_bootstrap[scalar_variables])\n",
    "    df_train_bootstrap[scalar_variables] = scaler.transform(df_train_bootstrap[scalar_variables])\n",
    "    df_test_bootstrap[scalar_variables] = scaler.transform(df_test_bootstrap[scalar_variables])\n",
    "\n",
    "    # Define the type of categorical variables as category.\n",
    "    for col in df_train_bootstrap[categorical_variables]:\n",
    "        df_train_bootstrap[col] = df_train_bootstrap[col].astype('category')\n",
    "        df_test_bootstrap[col] = df_test_bootstrap[col].astype('category')\n",
    "\n",
    "                        \n",
    "    auc_roc = []\n",
    "    variables = ['target']\n",
    "    columns = df_train_bootstrap.columns\n",
    "\n",
    "    for i in range(0,len(columns)):\n",
    "        auc_roc_best = 0\n",
    "        variables_test = []\n",
    "        variables_best = []\n",
    "\n",
    "        for j in range(0, len(columns)):\n",
    "            variables_test_aux = variables + [columns[j]]\n",
    "            variables_test = pd.unique(variables_test_aux)\n",
    "\n",
    "            if (len(variables_test) == len(variables_test_aux)):   # So we don't test the same model twice.\n",
    "                LightGBM = lgb.LGBMClassifier(**hyperparameters_LightGBM_dict)\n",
    "                # fit and predict\n",
    "                variables_test\n",
    "                LightGBM_fit = LightGBM.fit(df_train_bootstrap[variables_test[1:]], y_train)\n",
    "                y_pred_test = LightGBM_fit.predict_proba(df_test_bootstrap[variables_test[1:]])[:,1]\n",
    "                auc_roc_aux = roc_auc_score(y_test, y_pred_test)\n",
    "                if auc_roc_aux > auc_roc_best:\n",
    "                    variables_best = columns[j]\n",
    "                    auc_roc_best = auc_roc_aux\n",
    "\n",
    "        variables = variables + [variables_best]\n",
    "        auc_roc = auc_roc + [auc_roc_best]\n",
    "    # Save final results      \n",
    "    df_variables_lightgbm[cross_i] = variables\n",
    "    df_auc_roc_lightgbm[cross_i] = auc_roc\n",
    "    print(cross_i)\n",
    "variables_count = np.arange(start = 1, stop = len(variables), step = 1)\n",
    "df_variables_lightgbm['qnt_variables'] = df_variables_lightgbm.index\n",
    "df_auc_roc_lightgbm['qnt_variables'] = variables_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe488e-44d9-4da0-82fb-239fe9b9a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxpot of ROC per quantity of variables used\n",
    "df_auc_roc_lightgbm_2 = pd.melt(df_auc_roc_lightgbm, id_vars = ['qnt_variables'], value_vars = [0, 1, 2], var_name = 'cros_val', value_name = 'roc_auc')\n",
    "title = 'Performance by used variables' \n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "sns.set(rc = {'figure.figsize': (10, 6)})\n",
    "bg_color = \"white\"\n",
    "contorno = 'black'\n",
    "color = 'black'\n",
    "sns.set_style(\"darkgrid\", {'axes.facecolor': bg_color\n",
    "                          , 'axes.edgecolor': contorno})\n",
    "meanpointprops = dict(color = color, linewidth = 1.5)\n",
    "\n",
    "ax = sns.boxplot(y = 'roc_auc', data = df_auc_roc_lightgbm_2, x = 'qnt_variables'  #, order = hue_order\n",
    "                    , showmeans = True, meanline = True, meanprops = meanpointprops)\n",
    "ax.set_title(title, fontsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78631bc7-1b7f-4c38-82de-adcd763eee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify which variables were used for each model. \n",
    "# There are some randomness in each model. Therefore, we need a heat map showing the proportion of how many times each variable was used in the cross-validation. \n",
    "df_variables_lightgbm_heatmap = (df_variables_lightgbm.iloc[1:,:-1].apply(pd.Series.value_counts, axis=1).fillna(0)) / 10\n",
    "df_variables_lightgbm_heatmap = df_variables_lightgbm_heatmap.cumsum()\n",
    "df_variables_lightgbm_heatmap = df_variables_lightgbm_heatmap.replace({0: np.nan})\n",
    "\n",
    "size_x = 10\n",
    "size_y = 10\n",
    "plt.figure(figsize = (size_x, size_y))\n",
    "sns.set(font_scale = 1)\n",
    "corr_matrix = df.corr()\n",
    "with sns.axes_style('white'):\n",
    "    ax = sns.heatmap(df_variables_lightgbm_heatmap.T\n",
    "                    , linewidth = 0.2\n",
    "                    , annot = True, fmt = '.1f'\n",
    "                    , cmap = 'seismic'\n",
    "                    , vmin = -1, vmax = 1)\n",
    "plt.title(title)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694580c-8920-4cb3-98a7-efc25b1c3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance for train and test for each hyperparameter used.\n",
    "def print_plot_best_hyperparameter_result(df, maximum_minimum, tested_parameter, metric_name):\n",
    "    '''\n",
    "    This function must receive a Pandas DataFrame.\n",
    "    The first columns must be the parameters tested.\n",
    "    The second column must be the results for the train dataset\n",
    "    The third column must be the results for the test dataset\n",
    "    '''\n",
    "    # Find best parameter and print\n",
    "    if maximum_minimum == 'maximum':\n",
    "        best_parameter_result = df.iloc[:,2].max()\n",
    "    elif maximum_minimum == 'minimum':\n",
    "        best_parameter_result = df.iloc[:,2].min()\n",
    "    print('Used metric:', metric_name)\n",
    "    print('Best', tested_parameter, 'parameter:', df[np.in1d(df.iloc[:,2], best_parameter_result)].iloc[:,0].values[0])\n",
    "    print('Best', tested_parameter, 'parameter result:', best_parameter_result, '\\n')\n",
    "\n",
    "    # Plot train test results\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    parameters_tested = df.iloc[:,0]\n",
    "    train_results = df.iloc[:,1]\n",
    "    test_results = df.iloc[:,2]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    # Plot first the results for train\n",
    "    ax.plot(parameters_tested, train_results, color='red', linewidth = 0.7, linestyle = 'solid', label = 'Train')\n",
    "    # Add dots in tested points\n",
    "    ax.scatter(parameters_tested, train_results, s = 8, color = 'black')\n",
    "\n",
    "    # Plot the results for test\n",
    "    ax.plot(parameters_tested, test_results, color='blue', linewidth = 0.7, linestyle = 'solid', label = 'Test')\n",
    "    # Add dots in tested points\n",
    "    ax.scatter(parameters_tested, test_results, s = 8, color = 'black')\n",
    "\n",
    "\n",
    "    ax.legend(loc = 'lower center', bbox_to_anchor=(0.5, -0.18))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cecd495-e98d-4245-aa29-8e97c5bc44ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65738e-e47e-4ee5-ac33-701ec214dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some hyperparameters for LightGBM Classifier\n",
    "def hyperparameter_LGBMClassifier(X_train, y_train, X_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters):\n",
    "    '''\n",
    "    hiperparametros:\n",
    "    random_state\n",
    "    n_estimators, default=100. The number of trees in the forest.\n",
    "    loss{'log_loss', 'exponential'}, default = 'log_loss'\n",
    "    learning_rate, default=0.1. It ranges from 0 to inf\n",
    "    subsample, default=1.0. It ranges from 0 to 1\n",
    "    criterion{'friedman_mse', 'squared_error'}, default=’friedman_mse’\n",
    "    num_iterations: 100\n",
    "    min_samples_split, default=2\n",
    "    min_samples_leaf, default=1\n",
    "    max_depth, default = 3  \n",
    "    lambda_l1: 0\n",
    "    lambda_l2: 0\n",
    "    cat_l2: 10\n",
    "    cat_smooth: 10\n",
    "    '''\n",
    "    returned_values = {}\n",
    "    metrica_comparacao_train = []\n",
    "    metrica_comparacao_test = []\n",
    "    parameters_tested = []\n",
    "    for parameter in test_hyperparameters:\n",
    "        parameters_tested.append(parameter)\n",
    "        # change the value of the teted hyperparameter.\n",
    "        hyperparameters_dict[hyperparameter_test_name] = parameter\n",
    "        # Set model hyperparameters\n",
    "        clf = lgb.LGBMClassifier(**hyperparameters_dict)\n",
    "        \n",
    "        # fit and predict\n",
    "        clf_fit = clf.fit(X_train, y_train)\n",
    "        y_pred_train = clf_fit.predict_proba(X_train)[:,1]\n",
    "        y_pred_test = clf_fit.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        # Save metrics to compare the performance\n",
    "        metrica_comparacao_train.append(roc_auc_score(y_train, y_pred_train))\n",
    "        metrica_comparacao_test.append(roc_auc_score(y_test, y_pred_test))\n",
    "        \n",
    "    # Save results\n",
    "    metrica_comparacao_df = pd.DataFrame(list(zip(parameters_tested, metrica_comparacao_train, metrica_comparacao_test)), columns = ['parameter', 'roc_auc_score_train', 'roc_auc_score_test'])\n",
    "    \n",
    "    # Return the best hyperparameter and table with metrics\n",
    "    returned_values[hyperparameter_test_name] = metrica_comparacao_df[np.in1d(metrica_comparacao_df['roc_auc_score_test'], metrica_comparacao_df['roc_auc_score_test'].max())]['parameter'].values[0]\n",
    "    returned_values['resultados'] = metrica_comparacao_df\n",
    "    return returned_values\n",
    "\n",
    "df_train = df_train_bootstrap[variaveis_escolhidas_lightgbm]\n",
    "df_test = df_test_bootstrap[variaveis_escolhidas_lightgbm]\n",
    "\n",
    "hyperparameters_dict = {\"objective\": \"binary\",\n",
    "            \"metric\": \"binary_logloss\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            'verbose': -1,\n",
    "            'seed': 1,\n",
    "            \"num_iterations\": 300,\n",
    "            \"min_data_in_leaf\": 3000,\n",
    "            \"num_leaves\": 8,\n",
    "            \"max_depth\": 7,\n",
    "            \"feature_fraction\": 0.45,\n",
    "            \"learning_rate\": 0.12,\n",
    "            \"lambda_l1\": 0.001,\n",
    "            \"lambda_l2\": 0.01,\n",
    "            \"cat_l2\": 10,\n",
    "            \"cat_smooth\": 10}  \n",
    "\n",
    "\n",
    "# Test num_iterations\n",
    "print('Test num_iterations:  from 50 to 500.')\n",
    "hyperparameter_test_name = 'num_iterations'\n",
    "test_hyperparameters = np.arange(start = 50, stop = 501, step = 50)\n",
    "hyperparameter_result = hyperparameter_LGBMClassifier(df_train, y_train, df_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters)\n",
    "# Plot results\n",
    "df_hyperparameter_result_resultados = hyperparameter_result['resultados'].copy()\n",
    "tested_parameter = hyperparameter_test_name\n",
    "maximum_minimum = 'maximum'\n",
    "metric_name = 'ROC AUC'\n",
    "print_plot_best_hyperparameter_result(df_hyperparameter_result_resultados, maximum_minimum, tested_parameter, metric_name)\n",
    "# Save best result.\n",
    "hyperparameters_dict[hyperparameter_test_name] = hyperparameter_result[hyperparameter_test_name]\n",
    "\n",
    "# Test min_data_in_leaf\n",
    "print('Test min_data_in_leaf:  from 3000 to 7000.')\n",
    "hyperparameter_test_name = 'min_data_in_leaf'\n",
    "test_hyperparameters = [3000, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 5000, 6000, 7000]\n",
    "hyperparameter_result = hyperparameter_LGBMClassifier(df_train, y_train, df_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters)\n",
    "# Plot results\n",
    "df_hyperparameter_result_resultados = hyperparameter_result['resultados'].copy()\n",
    "tested_parameter = hyperparameter_test_name\n",
    "maximum_minimum = 'maximum'\n",
    "metric_name = 'ROC AUC'\n",
    "print_plot_best_hyperparameter_result(df_hyperparameter_result_resultados, maximum_minimum, tested_parameter, metric_name)\n",
    "# Save best result.\n",
    "hyperparameters_dict[hyperparameter_test_name] = hyperparameter_result[hyperparameter_test_name]\n",
    "                        \n",
    "# Test feature_fraction\n",
    "print('Test feature_fraction: from 0.05 to 1.')\n",
    "hyperparameter_test_name = 'feature_fraction'\n",
    "test_hyperparameters = np.arange(start = 0.05, stop = 1, step = 0.05)\n",
    "hyperparameter_result = hyperparameter_LGBMClassifier(df_train, y_train, df_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters)\n",
    "# Plot results\n",
    "df_hyperparameter_result_resultados = hyperparameter_result['resultados'].copy()\n",
    "tested_parameter = hyperparameter_test_name\n",
    "maximum_minimum = 'maximum'\n",
    "metric_name = 'ROC AUC'\n",
    "print_plot_best_hyperparameter_result(df_hyperparameter_result_resultados, maximum_minimum, tested_parameter, metric_name)\n",
    "# Save best result.\n",
    "hyperparameters_dict[hyperparameter_test_name] = hyperparameter_result[hyperparameter_test_name]    \n",
    "    \n",
    "# Test lambda_l1\n",
    "print('Test lambda_l1: from 0.0001 to 400.')\n",
    "hyperparameter_test_name = 'lambda_l1'\n",
    "test_hyperparameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 7, 10, 25, 50, 100, 150, 200, 250, 300, 350, 400]\n",
    "hyperparameter_result = hyperparameter_LGBMClassifier(df_train, y_train, df_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters)\n",
    "# Plot results\n",
    "df_hyperparameter_result_resultados = hyperparameter_result['resultados'].copy()\n",
    "tested_parameter = hyperparameter_test_name\n",
    "maximum_minimum = 'maximum'\n",
    "metric_name = 'ROC AUC'\n",
    "print_plot_best_hyperparameter_result(df_hyperparameter_result_resultados, maximum_minimum, tested_parameter, metric_name)\n",
    "# Save best result.\n",
    "hyperparameters_dict[hyperparameter_test_name] = hyperparameter_result[hyperparameter_test_name]   \n",
    "\n",
    "# Test lambda_l2\n",
    "print('Test lambda_l2: from 0.0001 to 400.')\n",
    "hyperparameter_test_name = 'lambda_l2'\n",
    "test_hyperparameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 7, 10, 25, 50, 100, 150, 200, 250, 300, 350, 400]\n",
    "hyperparameter_result = hyperparameter_LGBMClassifier(df_train, y_train, df_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters)\n",
    "# Plot results\n",
    "df_hyperparameter_result_resultados = hyperparameter_result['resultados'].copy()\n",
    "tested_parameter = hyperparameter_test_name\n",
    "maximum_minimum = 'maximum'\n",
    "metric_name = 'ROC AUC'\n",
    "print_plot_best_hyperparameter_result(df_hyperparameter_result_resultados, maximum_minimum, tested_parameter, metric_name)\n",
    "# Save best result.\n",
    "hyperparameters_dict[hyperparameter_test_name] = hyperparameter_result[hyperparameter_test_name] \n",
    "\n",
    "# Test cat_l2\n",
    "print('Test cat_l2: from 0.0001 to 400.')\n",
    "hyperparameter_test_name = 'cat_l2'\n",
    "test_hyperparameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 25, 50, 100, 150, 200, 250, 300, 350, 400]\n",
    "hyperparameter_result = hyperparameter_LGBMClassifier(df_train, y_train, df_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters)\n",
    "# Plot results\n",
    "df_hyperparameter_result_resultados = hyperparameter_result['resultados'].copy()\n",
    "tested_parameter = hyperparameter_test_name\n",
    "maximum_minimum = 'maximum'\n",
    "metric_name = 'ROC AUC'\n",
    "print_plot_best_hyperparameter_result(df_hyperparameter_result_resultados, maximum_minimum, tested_parameter, metric_name)\n",
    "# Save best result.\n",
    "hyperparameters_dict[hyperparameter_test_name] = hyperparameter_result[hyperparameter_test_name] \n",
    "\n",
    "# Test cat_smooth\n",
    "print('Test cat_smooth: from 0.0001 to 400.')\n",
    "hyperparameter_test_name = 'cat_smooth'\n",
    "test_hyperparameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 25, 50, 100, 150, 200, 250, 300, 350, 400]\n",
    "hyperparameter_result = hyperparameter_LGBMClassifier(df_train, y_train, df_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters)\n",
    "# Plot results\n",
    "df_hyperparameter_result_resultados = hyperparameter_result['resultados'].copy()\n",
    "tested_parameter = hyperparameter_test_name\n",
    "maximum_minimum = 'maximum'\n",
    "metric_name = 'ROC AUC'\n",
    "print_plot_best_hyperparameter_result(df_hyperparameter_result_resultados, maximum_minimum, tested_parameter, metric_name)\n",
    "# Save best result.\n",
    "hyperparameters_dict[hyperparameter_test_name] = hyperparameter_result[hyperparameter_test_name] \n",
    "\n",
    "# Test num_leaves\n",
    "print('Test num_leaves:  from 10 to 40.')\n",
    "hyperparameter_test_name = 'num_leaves'\n",
    "test_hyperparameters = np.arange(start = 5, stop = 21, step = 1)\n",
    "hyperparameter_result = hyperparameter_LGBMClassifier(df_train, y_train, df_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters)\n",
    "# Plot results\n",
    "df_hyperparameter_result_resultados = hyperparameter_result['resultados'].copy()\n",
    "tested_parameter = hyperparameter_test_name\n",
    "maximum_minimum = 'maximum'\n",
    "metric_name = 'ROC AUC'\n",
    "print_plot_best_hyperparameter_result(df_hyperparameter_result_resultados, maximum_minimum, tested_parameter, metric_name)\n",
    "# Save best result.\n",
    "hyperparameters_dict[hyperparameter_test_name] = hyperparameter_result[hyperparameter_test_name]\n",
    "                        \n",
    "                        \n",
    "# Test max_depth\n",
    "print('Test max_depth:  from 2 to 30.')\n",
    "hyperparameter_test_name = 'max_depth'\n",
    "test_hyperparameters = np.arange(start = 2, stop = 16, step = 1)\n",
    "hyperparameter_result = hyperparameter_LGBMClassifier(df_train, y_train, df_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters)\n",
    "# Plot results\n",
    "df_hyperparameter_result_resultados = hyperparameter_result['resultados'].copy()\n",
    "tested_parameter = hyperparameter_test_name\n",
    "maximum_minimum = 'maximum'\n",
    "metric_name = 'ROC AUC'\n",
    "print_plot_best_hyperparameter_result(df_hyperparameter_result_resultados, maximum_minimum, tested_parameter, metric_name)\n",
    "# Save best result.\n",
    "hyperparameters_dict[hyperparameter_test_name] = hyperparameter_result[hyperparameter_test_name]\n",
    "                        \n",
    "                        \n",
    "# Test learning_rate\n",
    "print('Test learning_rate:  from 0.1 to 0.7.')\n",
    "hyperparameter_test_name = 'learning_rate'\n",
    "test_hyperparameters = np.arange(start = 0.01, stop = 0.701, step = 0.01)\n",
    "hyperparameter_result = hyperparameter_LGBMClassifier(df_train, y_train, df_test, y_test, hyperparameters_dict, hyperparameter_test_name, test_hyperparameters)\n",
    "# Plot results\n",
    "df_hyperparameter_result_resultados = hyperparameter_result['resultados'].copy()\n",
    "tested_parameter = hyperparameter_test_name\n",
    "maximum_minimum = 'maximum'\n",
    "metric_name = 'ROC AUC'\n",
    "print_plot_best_hyperparameter_result(df_hyperparameter_result_resultados, maximum_minimum, tested_parameter, metric_name)\n",
    "# Save best result.\n",
    "hyperparameters_dict[hyperparameter_test_name] = hyperparameter_result[hyperparameter_test_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3790fd-4c08-472b-8a27-fb69ffe3c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "hyperparameters_dict = {\"objective\": \"binary\",\n",
    "            \"metric\": \"binary_logloss\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            'verbose': -1,\n",
    "            'seed': 1,\n",
    "            \"num_iterations\": 300,\n",
    "            \"min_data_in_leaf\": 3000,\n",
    "            \"num_leaves\": 8,\n",
    "            \"max_depth\": 7,\n",
    "            \"feature_fraction\": 0.45,\n",
    "            \"learning_rate\": 0.12,\n",
    "            \"lambda_l1\": 0.001,\n",
    "            \"lambda_l2\": 0.01,\n",
    "            \"cat_l2\": 10,\n",
    "            \"cat_smooth\": 10}  \n",
    "\n",
    "lightGBM = lgb.LGBMClassifier(**hyperparameters_dict)\n",
    "# fit and predict\n",
    "lightGBM_fit = lightGBM.fit(df_train, y_train)\n",
    "y_pred_train = lightGBM_fit.predict_proba(df_train)[:,1]\n",
    "y_pred_test = lightGBM_fit.predict_proba(df_test)[:,1]\n",
    "    \n",
    "# Marca 0 ou 1 para y_pred\n",
    "y_train_pred_binario = []\n",
    "for e in y_pred_train:\n",
    "    if e < 0.5:\n",
    "        y_train_pred_binario.append(0)\n",
    "    else:\n",
    "        y_train_pred_binario.append(1)    \n",
    "\n",
    "# Marca 0 ou 1 para y_pred\n",
    "y_test_pred_binario = []\n",
    "for e in y_pred_test:\n",
    "    if e < 0.5:\n",
    "        y_test_pred_binario.append(0)\n",
    "    else:\n",
    "        y_test_pred_binario.append(1)\n",
    "        \n",
    "# Out of time\n",
    "y_pred_out_of_time = lightGBM_fit.predict_proba(df_out_of_time_2)[:,1]\n",
    "# Marca 0 ou 1 para y_pred_out_of_time\n",
    "y_pred_out_of_time_binario = []\n",
    "for e in y_pred_out_of_time:\n",
    "    if e < 0.5:\n",
    "        y_pred_out_of_time_binario.append(0)\n",
    "    else:\n",
    "        y_pred_out_of_time_binario.append(1)\n",
    "\n",
    "print()\n",
    "print('Proportion of target = 1 in test:', np.mean(y_test))\n",
    "print('Proportion of target = 1 predicted in test:', np.mean(y_test_pred_binario))\n",
    "print('Proportion of target = 1 in out of time:', np.mean(y_out_of_time))\n",
    "print('Proportion of target = 1 predicted in out of time:', np.mean(y_pred_out_of_time_binario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c8b65-80a9-4977-a54e-7ed69bfb2ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify feature importance for LightGBM.   \n",
    "lgb.plot_importance(lightGBM, grid = False, figsize = (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a6fb1-3b39-4b92-9769-9c88a60f6432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some metrics of our model.\n",
    "def roc_curve_graph(y_true, y_pred, title):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "def matriz_confusao(y_true, y_pred, title):\n",
    "    # Matriz de confusão\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    group_names = ['True Neg','False Pos','False Neg', 'True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "    ax.set_xlabel('\\nPredicted values')\n",
    "    ax.set_ylabel('Actual values')\n",
    "    ax.set_title(title, fontsize = 10)\n",
    "    ax.xaxis.set_ticklabels(['0','1'])\n",
    "    ax.yaxis.set_ticklabels(['0','1'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def metrics(y_real, y_pred, y_pred_binario):\n",
    "    roc = roc_auc_score(y_real, y_pred)\n",
    "    accuracy = accuracy_score(y_real, y_pred_binario)\n",
    "    precisao = precision_score(y_real, y_pred_binario)\n",
    "    recall = recall_score(y_real, y_pred_binario)\n",
    "    f1 = f1_score(y_real, y_pred_binario)\n",
    "\n",
    "    print('roc:', roc)\n",
    "    print('accuracy:', accuracy)\n",
    "    print('precision:', precisao)\n",
    "    print('recall:', recall)\n",
    "    print('f1:', f1)\n",
    "    print()\n",
    "\n",
    "    title = 'Confusion matrix LightGBM: out of time.'\n",
    "    matriz_confusao(y_real, y_pred_binario, title)\n",
    "\n",
    "    # ROC curves, Cumulative gains, and KS - Out of Time\n",
    "    print('ROC, Cumulative Gains, KS: Out of Time')\n",
    "    y_out_of_time_pred_0 = 1 - y_pred \n",
    "    y_out_of_time_prob = list(zip(y_out_of_time_pred_0, y_pred))\n",
    "    skplt.metrics.plot_roc(y_real, y_out_of_time_prob)\n",
    "    skplt.metrics.plot_cumulative_gain(y_real, y_out_of_time_prob)\n",
    "    skplt.metrics.plot_ks_statistic(y_real, y_out_of_time_prob)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "metrics(y_train, y_pred_train, y_train_pred_binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d020824-941c-4b27-8e5e-21555db34a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the potential gain in using the model\n",
    "def tabela_recall(df, y_pred):\n",
    "    df.loc[:,'POTENCIAL_GAIN'] = df_out_of_time['vl_opr'] \n",
    "\n",
    "    # Cria as faixas de estudo\n",
    "    bins_probabilidade = [np.NINF, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, np.Inf] # Cortes definido no treino\n",
    "    df.loc[:,'PROBABILITY_CUT'] = pd.cut(df[y_pred], bins = bins_probabilidade\n",
    "                                                 , labels = [\"0-10%\", \"10-20%\", \"20-30%\", \"30-40%\", \"40-50%\", \"50-60%\", \"60-70%\", \"70-80%\", \"80-90%\", \"90-100%\"])\n",
    "    df_potencial_faixa = df[['POTENCIAL_GAIN', 'PROBABILITY_CUT']].groupby(by = ['PROBABILITY_CUT'], dropna = False).sum()\n",
    "    \n",
    "\n",
    "    # Calculo da quantidade de clientes em potenciais\n",
    "    df_clientes_faixa = df[['POTENCIAL_GAIN', 'PROBABILITY_CUT']].groupby(by = ['PROBABILITY_CUT'], dropna = False).size()\n",
    "    df_potencial_faixa['POTENTIAL_CUSTOMERS'] = df_clientes_faixa\n",
    "    df_potencial_faixa['% BASE'] = (df_potencial_faixa['POTENTIAL_CUSTOMERS'] / df_potencial_faixa['POTENTIAL_CUSTOMERS'].sum()).map('{:,.1%}'.format)\n",
    "    # Calculo da quantidade de clientes que realmente contrataram\n",
    "    df_contrataram_faixa = df[['target', 'PROBABILITY_CUT']].groupby(by = ['PROBABILITY_CUT'], dropna = False).sum()\n",
    "    df_potencial_faixa['TARGET_1'] = df_contrataram_faixa\n",
    "\n",
    "    df_potencial_faixa['TARGET_0'] = df_potencial_faixa['POTENTIAL_CUSTOMERS'] - df_potencial_faixa['TARGET_1']\n",
    "    df_potencial_faixa['PRECISION'] = (df_potencial_faixa['TARGET_1'] / df_potencial_faixa['POTENTIAL_CUSTOMERS']).map('{:,.1%}'.format)\n",
    "    df_potencial_faixa['RECALL'] = (df_potencial_faixa['TARGET_1']/df_potencial_faixa['TARGET_1'].sum()).map('{:,.1%}'.format)\n",
    "\n",
    "    # Calcula as métricas acumuladas\n",
    "    df_potencial_faixa.sort_index(ascending = False, inplace = True)\n",
    "    df_potencial_faixa['POTENTIAL_CUSTOMERS_AC'] = df_potencial_faixa[['POTENTIAL_CUSTOMERS']].cumsum()\n",
    "    df_potencial_faixa['% BASE AC'] = (df_potencial_faixa['POTENTIAL_CUSTOMERS_AC'] / df_potencial_faixa['POTENTIAL_CUSTOMERS'].sum()).map('{:,.1%}'.format)\n",
    "    df_potencial_faixa['TARGET_1_AC'] = df_potencial_faixa[['TARGET_1']].cumsum()\n",
    "    df_potencial_faixa['PRECISION_AC'] = (df_potencial_faixa['TARGET_1_AC'] / df_potencial_faixa['POTENTIAL_CUSTOMERS_AC']).map('{:,.1%}'.format)\n",
    "    df_potencial_faixa['RECALL_AC'] = (df_potencial_faixa['TARGET_1_AC']/df_potencial_faixa['TARGET_1'].sum()).map('{:,.1%}'.format)\n",
    "    df_potencial_faixa['POTENCIAL_GAIN_AC'] = df_potencial_faixa[['POTENCIAL_GAIN']].cumsum()\n",
    "    df_potencial_faixa.loc[:,'POTENCIAL_GAIN'] = df_potencial_faixa['POTENCIAL_GAIN'].map('{:,.2f}'.format)\n",
    "    df_potencial_faixa.loc[:,'POTENCIAL_GAIN_AC'] = df_potencial_faixa['POTENCIAL_GAIN_AC'].map('{:,.2f}'.format)\n",
    "\n",
    "    # Reordena as colunas\n",
    "    df_potencial_faixa = df_potencial_faixa[['POTENTIAL_CUSTOMERS', 'POTENTIAL_CUSTOMERS_AC', '% BASE', '% BASE AC'\n",
    "                                     , 'TARGET_1', 'TARGET_0', 'TARGET_1_AC', 'PRECISION', 'PRECISION_AC', 'RECALL' ,'RECALL_AC', 'POTENCIAL_GAIN', 'POTENCIAL_GAIN_AC']]\n",
    "    return df_potencial_faixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4830a-5c76-4379-a5d6-b089dd131797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show table with potential gain of using our model.\n",
    "df_out_of_time_3 = df_out_of_time.copy()\n",
    "df_out_of_time_3['y_pred_out_of_time'] = y_pred_out_of_time\n",
    "print('Return table, período out of time:')\n",
    "return_table_out_of_time = tabela_recall(df_out_of_time_3, 'y_pred_out_of_time')\n",
    "display(return_table_out_of_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
